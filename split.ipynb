{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95fe3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split Large TXT File into 100MB Chunks ---\n",
    "\n",
    "import os\n",
    "\n",
    "# ======== CONFIGURATION ========\n",
    "input_file = \"ne.txt\"   # Path to your large .txt file\n",
    "output_dir = \"split_files\"           # Folder to store output files\n",
    "chunk_size_mb = 100                  # Chunk size in megabytes\n",
    "# =================================\n",
    "\n",
    "# Create output directory if not exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "chunk_size = chunk_size_mb * 1024 * 1024  # Convert MB to bytes\n",
    "file_number = 1\n",
    "bytes_written = 0\n",
    "\n",
    "output_path = os.path.join(output_dir, f\"part_{file_number}.txt\")\n",
    "out_file = open(output_path, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile:\n",
    "    for line in infile:\n",
    "        out_file.write(line)\n",
    "        bytes_written += len(line.encode(\"utf-8\"))\n",
    "\n",
    "        # If current file exceeds chunk size, start a new one\n",
    "        if bytes_written >= chunk_size:\n",
    "            out_file.close()\n",
    "            print(f\"Created: {output_path}\")\n",
    "            file_number += 1\n",
    "            bytes_written = 0\n",
    "            output_path = os.path.join(output_dir, f\"part_{file_number}.txt\")\n",
    "            out_file = open(output_path, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "out_file.close()\n",
    "print(f\"Created: {output_path}\")\n",
    "print(\"✅ Splitting complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcfc1864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: part_1.txt\n",
      "Processing: part_10.txt\n",
      "Processing: part_11.txt\n",
      "Processing: part_12.txt\n",
      "Processing: part_13.txt\n",
      "Processing: part_14.txt\n",
      "Processing: part_15.txt\n",
      "Processing: part_16.txt\n",
      "Processing: part_17.txt\n",
      "Processing: part_18.txt\n",
      "Processing: part_19.txt\n",
      "Processing: part_2.txt\n",
      "Processing: part_20.txt\n",
      "Processing: part_21.txt\n",
      "Processing: part_22.txt\n",
      "Processing: part_23.txt\n",
      "Processing: part_24.txt\n",
      "Processing: part_25.txt\n",
      "Processing: part_26.txt\n",
      "Processing: part_27.txt\n",
      "Processing: part_28.txt\n",
      "Processing: part_29.txt\n",
      "Processing: part_3.txt\n",
      "Processing: part_30.txt\n",
      "Processing: part_31.txt\n",
      "Processing: part_32.txt\n",
      "Processing: part_33.txt\n",
      "Processing: part_34.txt\n",
      "Processing: part_35.txt\n",
      "Processing: part_36.txt\n",
      "Processing: part_37.txt\n",
      "Processing: part_38.txt\n",
      "Processing: part_39.txt\n",
      "Processing: part_4.txt\n",
      "Processing: part_5.txt\n",
      "Processing: part_6.txt\n",
      "Processing: part_7.txt\n",
      "Processing: part_8.txt\n",
      "Processing: part_9.txt\n",
      "✅ Cleaning complete. All files saved in: cleaned_files\n",
      "✅ Character frequency file created: cleaned_files\\character_frequency.txt\n",
      "✅ Symbols not found file created: cleaned_files\\symbols_not_found.txt\n",
      "Symbols not found: []\n"
     ]
    }
   ],
   "source": [
    "# --- Clean Text Files, Count Character Occurrences & Report Missing Symbols ---\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# ======== CONFIGURATION ========\n",
    "input_dir = \"split_files\"    # Directory containing the split .txt files\n",
    "output_dir = \"cleaned_files\" # Where cleaned files will be saved\n",
    "# =================================\n",
    "\n",
    "# Define allowed characters\n",
    "allowed_numbers = '०१२३४५६७८९0123456789'\n",
    "allowed_symbols = \"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{}~।॥—‘’“”… \"\n",
    "allowed_lang_chars = 'अआइईउऊऋएऐओऔअंअःकखगघङचछजझञटठडढणतथदधनपफबभमयरलवशषसहक्षत्रज्ञािीुूृेैोौंःँॅॉ'\n",
    "allowed_chars = set(allowed_numbers + allowed_symbols + allowed_lang_chars + '\\n')  # Keep newlines\n",
    "\n",
    "# Prepare output folder\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize global counter\n",
    "char_counter = Counter()\n",
    "\n",
    "# Process each file\n",
    "for filename in sorted(os.listdir(input_dir)):\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    print(f\"Processing: {filename}\")\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "        for line in infile:\n",
    "            cleaned_line = ''.join(ch for ch in line if ch in allowed_chars)\n",
    "            outfile.write(cleaned_line)\n",
    "            char_counter.update(cleaned_line)\n",
    "\n",
    "print(\"✅ Cleaning complete. All files saved in:\", output_dir)\n",
    "\n",
    "# Save character frequency dictionary\n",
    "freq_output_path = os.path.join(output_dir, \"character_frequency.txt\")\n",
    "with open(freq_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for ch, count in sorted(char_counter.items(), key=lambda x: -x[1]):\n",
    "        f.write(f\"{repr(ch)}: {count}\\n\")\n",
    "\n",
    "print(\"✅ Character frequency file created:\", freq_output_path)\n",
    "\n",
    "# Identify symbols not found at all\n",
    "symbols_not_found = [s for s in allowed_symbols if char_counter[s] == 0]\n",
    "\n",
    "missing_symbols_path = os.path.join(output_dir, \"symbols_not_found.txt\")\n",
    "with open(missing_symbols_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for s in symbols_not_found:\n",
    "        f.write(f\"{repr(s)}\\n\")\n",
    "\n",
    "print(\"✅ Symbols not found file created:\", missing_symbols_path)\n",
    "print(\"Symbols not found:\", symbols_not_found)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
